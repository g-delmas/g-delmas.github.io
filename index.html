<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
    <title>Ginger Delmas</title>
    <!-- Add icon library -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    <!-- Note: to check whether an icon is freely available, go to https://origin.fontawesome.com/v6/search?o=r&m=free ; and be sure to select the right version. An icon named as "fa-solid fa-envelope" should be indicated as "fas fa-envelope"; same for "fa-brand fa-google-scholar": "fab fa-google-scholar" etc...-->
	<style>
		body {
            max-width: 1200px ;
			padding: 6px 12px;
			font-family: 'Roboto', 'Noto', sans-serif;
            margin: auto;
            margin-bottom: 50px;
		}
        .section {
            margin-top: 50px;
            margin-bottom: 30px;
        }
        .section > p {
            font-size: 2rem;
            font-weight: bold;
            font-family: Arial, sans-serif;
            margin-bottom: 0;
        }
        a {
            font-weight: bold;
            color: rgb(99, 167, 235);
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        li {
            padding-bottom: 10px;
        }

        /* PROFILE SECTION */
        .thats-me {
            display: inline-block;
            vertical-align: middle;
            margin-right: 30px;
        }
        .thats-me > img {
            border-radius: 40px;
        }
        .profile-info {
            display: inline-block;
            vertical-align: middle;
            width: 670px;
            padding: 20px;
        }
        .profile-data-item {
            display: inline-block;
            color: black;
            border-radius: 5px;
            border: 3px solid rgb(250, 196, 103);
            background-color: rgb(250, 196, 103);
            padding: 5px;
            margin-right: 2px;
        }
        .profile-data-item:hover {
            border: 3px solid rgb(252, 174, 39);
            background-color: rgb(252, 174, 39);
        }
            
        /* PAPER SECTION */
        .paper {
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
            display: flex;
            flex-flow: row wrap;
            gap: 30px;
            align-items: center;
        }
        .paper-thumbnails {
            width: 400px;
            vertical-align: middle;
            text-align: center;
        }
        .paper-thumbnails > img {
            margin: 0 auto;
            max-width: 400px;
        }
        .paper-info {
            vertical-align: middle;
            max-width: 670px;
            padding: 20px;
        }
        .paper-title {
            font-weight: bold;
            font-size: larger;
        }
        .paper-status {
            font-style: italic;
        }
        .paper-status-chip {
            font-style: italic;
            font-weight: bold;
            color: rgb(255, 196, 0);
            background-color: black;
            border-radius: 16px;
            padding-left:10px;
            padding-right:10px;
            padding-top:2px;
            padding-bottom:2px;
        }
        .paper-small-descr {
            color: rgb(97, 97, 97);
            font-style: italic;
            font-size: medium;
            text-align: justify;
            opacity: 0;
            height: 0px;
        }
        .paper-small-descr.show {
            opacity: 1;
            height: auto;
            transition: opacity 0.5s ease-in-out;
        }
        .paper-data-item {
            display: inline-block;
            color: rgb(34, 134, 234);
            border: 2px solid rgb(99, 167, 235);
            border-radius: 10px;
            background-color: rgba(99, 167, 235, 0.294);
            padding: 5px;
            margin-right: 2px;
        }
        .paper-data-item:hover {
            background-color: rgba(55, 147, 238, 0.506);
            border: 2px solid rgb(99, 167, 235);
        }
        .paper-data-item-disabled {
            display: inline-block;
            color: white;
            border: 2px solid rgb(161, 161, 161);
            border-radius: 10px;
            background-color: rgb(161, 161, 161);
            padding: 5px;
            margin-right: 2px;
        }

        /* TALK SECTION */
        #talks > li {
            font-size: larger;
        }

        /* BIO SECTION */
        .bio {
            width: 60%;
            /* margin-inline: 20%; */
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        .bio-card {
            display: flex;
            background: white;
            overflow: visible;
            width: 100%;
            border-radius: 10px;
        }
        .bio-list {
            flex-grow: 1;
            padding: 20px;
            margin-top: auto;
            margin-bottom: auto;
        }
        .bio-date {
            font-size: 2rem;
            font-weight: bold;
            writing-mode: vertical-rl;
            /* FOR SWAPPING DATES AND TEXT: */
            /* transform: -rotate(180deg); */
            transform: rotate(180deg);
            display: flex;
            align-items: flex-end;
            justify-content: center;
            padding: 20px;
            border-top-right-radius: 10px;
            border-bottom-right-radius: 10px;
            background: rgba(250, 196, 103, 0.56);
            font-family: Arial, sans-serif;
        }

        /* The snackbar */
        
        #snackbar {
            visibility: hidden; /* Hidden by default. Visible on click */
            min-width: 250px; /* Set a default minimum width */
            margin-left: -125px; /* Divide value of min-width by 2 */
            background-color: #333; /* Black background color */
            color: #fff; /* White text color */
            text-align: center; /* Centered text */
            border-radius: 5px; /* Rounded borders */
            padding: 16px; /* Padding */
            position: fixed; /* Sit on top of the screen */
            z-index: 1; /* Add a z-index if needed */
            left: 50%; /* Center the snackbar */
            bottom: 30px; /* 30px from the bottom */
        }

        /* Show the snackbar when clicking on a button (class added with JavaScript) */
        #snackbar.show {
            visibility: visible; /* Show the snackbar */
            /* Add animation: Take 0.5 seconds to fade in and out the snackbar.
            However, delay the fade out process for 2.5 seconds */
            -webkit-animation: fadein 0.5s, fadeout 0.5s 2.5s;
            animation: fadein 0.5s, fadeout 0.5s 2.5s;
        }

        /* Animations to fade the snackbar in and out */
        @-webkit-keyframes fadein {
        from {bottom: 0; opacity: 0;}
        to {bottom: 30px; opacity: 1;}
        }

        @keyframes fadein {
        from {bottom: 0; opacity: 0;}
        to {bottom: 30px; opacity: 1;}
        }

        @-webkit-keyframes fadeout {
        from {bottom: 30px; opacity: 1;}
        to {bottom: 0; opacity: 0;}
        }

        @keyframes fadeout {
        from {bottom: 30px; opacity: 1;}
        to {bottom: 0; opacity: 0;}
        }
	</style>
    <script>


        function copy_email() {
            // Get the text to copy
            var copyText = 'ginger.delmas.pro -at- gmail.com'

            // Copy the text to clipboard
            navigator.clipboard.writeText(copyText);

            // Alert that the text was copied (temporary show the snackbar)
            var snackbar = document.getElementById("snackbar");
            snackbar.textContent = "Email address copied!"
            snackbar.className = "show";
            setTimeout(function(){ snackbar.className = snackbar.className.replace("show", ""); }, 3000);
        }


        function copy_bibtext(e) {
            // Get the text to copy
            var paper_name = e.parentNode.parentNode.parentNode.id;
            var copyText = document.getElementById(paper_name+"_bibtex").textContent;
            // remove initial tabulation
            var nb_useless_spaces = copyText.search(/\S/)-1; // get the initial number of spaces
            copyText = copyText.split("\n").slice(1); // remove initial empty line; split into lines
            copyText = [...copyText].map((v) => v.substr(nb_useless_spaces) ); // remove the space offset from each line
            copyText = copyText.join("\n"); // join lines into one text

            // Copy the text to clipboard
            navigator.clipboard.writeText(copyText);

            // Alert that the text was copied (temporary show the snackbar)
            var snackbar = document.getElementById("snackbar");
            snackbar.textContent = "BibTex copied!"
            snackbar.className = "show";
            setTimeout(function(){ snackbar.className = snackbar.className.replace("show", ""); }, 3000);
        }


        function know_more(e) {
            var paper_name = e.id;
            var description_element = document.getElementById(paper_name+"_descr");        
            description_element.classList.add("show");
        }

        
    </script>
</head>

<body>

    <div id="header">
        <div>
            <div class="thats-me">
                <img src="images/profile_picture.jpg">
            </div>
            <div class="profile-info">
                <h1>Ginger Delmas</h1>
                <h3>PhD student at <a href="https://www.iri.upc.edu/">IRI-UPC-CSIC</a> & <a href="https://europe.naverlabs.com/">NAVER LABS Europe</a>.</li></h3>
                <p>I am supervised by Francesc Moreno-Noguer, Philippe Weinzaepfel and Grégory Rogez. I am working on natural language texts and 3D human poses: my goal is to leverage text to improve human pose, shape, motion estimation and generation.</p>
                <div class="profile-data">
                    <a class="profile-data-item" onclick='copy_email()'><i class="fas fa-envelope"></i> Contact</a>
                    <a class="profile-data-item" href="documents/cv_Ginger_Delmas_webpage.pdf" target="_blank" rel="noopener noreferrer"><i class="fa fa-graduation-cap"></i> CV</a>
                    <a class="profile-data-item" href="https://fr.linkedin.com/in/ginger-delmas-a70b62192/en" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin-in"></i> Linkedin</a>
                    <a class="profile-data-item" href="https://scholar.google.com/citations?user=CmC-We4AAAAJ" target="_blank" rel="noopener noreferrer"><i class="fab fa-google-scholar"></i> Google Scholar</a>
                </div>
            </div>
        </div>
    </div>

    <!-- TOOLS -->
    <div id="snackbar"></div> 


    <!-- PAPERS -->
    <div>
        <div class="section">
            <p>Papers</p>
            <hr>
        </div>


        <!-- POSEEMBROIDER -->
        <div id="posembroider_eccv24" class="paper" onmouseenter='know_more(this)'>
            <div class="paper-thumbnails">
                <img src="images/PoseEmbroider_thumbnails.png">
            </div>
            <div class="paper-info">
                <span class="paper-status-chip">ECCV 2024</span>
                <p class="paper-title">PoseEmbroider: Towards a 3D, Visual, Semantic-aware Human Pose Representation</p>
                <p class="paper-authors">Ginger Delmas, Philippe Weinzaepfel, Francesc Moreno-Noguer, Grégory Rogez</p>
                <div class="paper-data">
                    <a class="paper-data-item" href="https://arxiv.org/pdf/2409.06535" target="_blank" rel="noopener noreferrer"></i><i class="far fa-file-pdf"></i> Paper</a>
                    <a class="paper-data-item" href="https://europe.naverlabs.com/research/PoseEmbroider/" target="_blank" rel="noopener noreferrer">&#127760; Webpage</a>
                    <a class="paper-data-item" href="https://github.com/naver/poseembroider" target="_blank" rel="noopener noreferrer"><i class="fa fa-code"></i> Code</a>
                    <!-- <a class="paper-data-item-disabled" href="https://europe.naverlabs.com/wp-content/uploads/todo" target="_blank" rel="noopener noreferrer"><i class="fas fa-panorama"></i> Poster</a> -->
                    <a class="paper-data-item" onclick='copy_bibtext(this)'>&#128278; BibTex</a>
                </div>
                <p id="posembroider_eccv24_descr" class="paper-small-descr">The PoseEmbroider framework combines multi-modal views of the human poses (images, textual descriptions, 3D joint rotations) to derive a rich visual-, semantic-, 3D-aware representation, which can be reused off-the-shelf in various downstream tasks (eg. any-to-any multi-modal retrieval, pose estimation, pose instruction generation). Its transformer core is trained in a contrastive fashion, and is shown to outperform the standard multi-modal alignment baseline.</p>
                <div id="posembroider_eccv24_bibtex" style="display: none;">
                    @inproceedings{delmas2024poseembroider,
                        title={{PoseEmbroider: Towards a 3D, Visual, Semantic-aware Human Pose Representation}},
                        author={{Delmas, Ginger and Weinzaepfel, Philippe and Moreno-Noguer, Francesc and Rogez, Gr\'egory}},
                        booktitle={{ECCV}},
                        year={2024}
                    }
                </div>
            </div>
        </div>

        <!-- POSEFIX -->
        <div id="posefix_iccv23" class="paper" onmouseenter='know_more(this)'>
            <div class="paper-thumbnails">
                <img src="images/PoseFix_thumbnails.png">
            </div>
            <div class="paper-info">
                <span class="paper-status-chip">ICCV 2023</span>
                <p class="paper-title">PoseFix: Correcting 3D Human Poses with Natural Language</p>
                <p class="paper-authors">Ginger Delmas, Philippe Weinzaepfel, Francesc Moreno-Noguer, Grégory Rogez</p>
                <div class="paper-data">
                    <a class="paper-data-item" href="https://arxiv.org/pdf/2309.08480.pdf" target="_blank" rel="noopener noreferrer"></i><i class="far fa-file-pdf"></i> Paper</a>
                    <a class="paper-data-item" href="https://europe.naverlabs.com/research/computer-vision/posefix/" target="_blank" rel="noopener noreferrer">&#127760; Webpage</a>
                    <a class="paper-data-item" href="https://github.com/naver/posescript" target="_blank" rel="noopener noreferrer"><i class="fa fa-code"></i> Code</a>
                    <a class="paper-data-item" href="https://europe.naverlabs.com/wp-content/uploads/2023/09/ICCV23_poster_10123_compressed.pdf" target="_blank" rel="noopener noreferrer"><i class="fas fa-panorama"></i> Poster</a>
                    <a class="paper-data-item" onclick='copy_bibtext(this)'>&#128278; BibTex</a>
                    <a class="paper-data-item" href="https://download.europe.naverlabs.com/ComputerVision/PoseFix/posefix_dataset_release.zip" target="_blank" rel="noopener noreferrer"><i class="fa fa-database"></i> Data</a>
                </div>
                <p id="posefix_iccv23_descr" class="paper-small-descr">We introduce the PoseFix dataset, which consists in over 6k triplets of 3D human pose pairs and a text modifier describing how the source pose needs to be modified to obtain the target pose. We further train a text-based pose editing model to generate corrected 3D body poses given a query pose and a text modifier; and a correctional text generation model, where correctional instructions are generated based on the differences between two body poses.</p>
                <div id="posefix_iccv23_bibtex" style="display: none;">
                    @inproceedings{delmas2023posefix,
                        title={{PoseFix: Correcting 3D Human Poses with Natural Language}},
                        author={{Delmas, Ginger and Weinzaepfel, Philippe and Moreno-Noguer, Francesc and Rogez, Gr\'egory}},
                        booktitle={{ICCV}},
                        year={2023}
                    }
                </div>
            </div>
        </div>

        <!-- POSESCRIPT -->
        <div id="posescript_eccv22" class="paper" onmouseenter='know_more(this)'>
            <div class="paper-thumbnails">
                <img src="images/PoseScript_thumbnails.png">
            </div>
            <div class="paper-info">
                <span class="paper-status-chip">ECCV 2022</span>
                <span class="paper-status-chip">TPAMI 2024</span>
                <p class="paper-title">PoseScript: 3D Human Poses from Natural Language</p>
                <p class="paper-authors">Ginger Delmas, Philippe Weinzaepfel, Thomas Lucas, Francesc Moreno-Noguer, Grégory Rogez</p>
                <div class="paper-data">
                    <a class="paper-data-item" href="https://arxiv.org/pdf/2210.11795.pdf" target="_blank" rel="noopener noreferrer"><i class="far fa-file-pdf"></i> Paper</a>
                    <a class="paper-data-item" href="https://europe.naverlabs.com/research/computer-vision/posescript/" target="_blank" rel="noopener noreferrer">&#127760; Webpage</a>
                    <a class="paper-data-item" href="https://github.com/naver/posescript" target="_blank" rel="noopener noreferrer"><i class="fa fa-code"></i> Code</a>
                    <a class="paper-data-item" href="https://europe.naverlabs.com/wp-content/uploads/2022/10/posescript_eccv_poster.pdf" target="_blank" rel="noopener noreferrer"><i class="fas fa-panorama"></i> Poster</a>
                    <a class="paper-data-item" onclick='copy_bibtext(this)'>&#128278; BibTex</a>
                    <a class="paper-data-item" href="https://download.europe.naverlabs.com/ComputerVision/PoseScript/posescript_release_v2.zip" target="_blank" rel="noopener noreferrer"><i class="fa fa-database"></i> Data</a>
                </div>
                <p id="posescript_eccv22_descr" class="paper-small-descr">We collect a dataset, PoseScript, pairing 3D human poses from AMASS and descriptions both written by human annotators and generated automatically by our proposed pipeline. We use PoseScript to train text-to-pose models, both for retrieval and generation. Pretraining on automatic data boost performance by a factor 2.</p>
                <div id="posescript_eccv22_bibtex" style="display: none;">
                    @inproceedings{delmas_posescript,
                        title={{PoseScript: Linking 3D Human Poses and Natural Language}},
                        author={{Delmas, Ginger and Weinzaepfel, Philippe and Lucas, Thomas and Moreno-Noguer, Francesc and Rogez, Gr\'egory}},
                        journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
                        year={2024},
                        doi={10.1109/TPAMI.2024.3407570}
                    }
                </div>
            </div>
        </div>

        <!-- ARTEMIS -->
        <div id="artemis_iclr22" class="paper" onmouseenter='know_more(this)'>
            <div class="paper-thumbnails">
                <img src="images/ARTEMIS_thumbnails.png">
            </div>
            <div class="paper-info">
                <span class="paper-status-chip">ICLR 2022</span>
                <p class="paper-title">ARTEMIS: Attention-based Retrieval with Text-Explicit Matching and Implicit Similarity</p>
                <p class="paper-authors">Ginger Delmas, Rafael Sampaio De Rezende, Gabriela Csurka, Diane Larlus</p>
                <div class="paper-data">
                    <a class="paper-data-item" href="https://openreview.net/pdf?id=CVfLvQq9gLo" target="_blank" rel="noopener noreferrer"><i class="far fa-file-pdf"></i> Paper</a>
                    <a class="paper-data-item" href="https://europe.naverlabs.com/research/computer-vision/artemis/" target="_blank" rel="noopener noreferrer">&#127760; Webpage</a>
                    <a class="paper-data-item" href="https://github.com/naver/artemis" target="_blank" rel="noopener noreferrer"><i class="fa fa-code"></i> Code</a>
                    <a class="paper-data-item" href="https://europe.naverlabs.com/wp-content/uploads/2022/10/ARTEMIS_ICLR_poster_final.png" target="_blank" rel="noopener noreferrer"><i class="fas fa-panorama"></i> Poster</a>
                    <a class="paper-data-item" onclick='copy_bibtext(this)'>&#128278; BibTex</a>
                </div>
                <p id="artemis_iclr22_descr" class="paper-small-descr">We take inspiration from image retrieval and cross-modal retrieval to tackle the task of composed image retrieval: we design two complementary modules, each focusing on one modality of the query. The Explicit Matching module assesses how potential targets fit the textual modifier while the Implicit Similarity module compares potential target images to the reference image, assisted by the text. We validate our approach on FashionIQ, Shoes and CIRR.</p>
                <div id="artemis_iclr22_bibtex" style="display: none;">
                    @InProceedings{delmas2022artemis,
                        title={Artemis: Attention-based retrieval with text-explicit matching and implicit similarity},
                        author={Delmas, Ginger and de Rezende, Rafael Sampaio and Csurka, Gabriela and Larlus, Diane},
                        booktitle={ICLR},
                        year={2022}
                    }
                </div>
            </div>
        </div>

    </div>

    <!-- TALKS -->
    <div id="talks">
        <div class="section">
            <p>Talks</p>
            <hr>
        </div>
        <ul>
            <li><a href="https://www.iri.upc.edu/workshops/RoboticsAISummerSchool2024/" target="_blank" rel="noopener noreferrer">Robotics, Control Systems & AI summer school, 2024</a>: Linking 3D human poses and texts.</li>
            <li><a href="https://sites.google.com/view/dlbcn2023/program/talks?authuser=0" target="_blank" rel="noopener noreferrer">DLBCN 2023</a>: PoseFix: Correcting 3D Human Poses with Natural Language (<a href="https://www.youtube.com/live/mWY45fPRUK4?feature=shared&t=12420" target="_blank" rel="noopener noreferrer">recording</a>).</li>
            <li><a href="https://sites.google.com/view/dlbcn2022/program/talks?authuser=0" target="_blank" rel="noopener noreferrer">DLBCN 2022</a>: PoseScript: 3D Human Poses from Natural Language.</li>
        </ul>

    </div>
    
    <!-- BIOGRAPHY -->
    <div>
        <div class="section">
            <p>Biography</p>
            <hr>
        </div>
        <div class="bio">
            
            <div class="bio-card">
                <div class="bio-date">2024</div>
                <div class="bio-list">
                    <ul>
                        <li>Interning at Amazon (Seattle, USA)</li>
                        <li>&#x2728; Outstanding reviewer awards (CVPR, ECCV).</li>
                        <li>&#x2728; Accepted TPAMI journal extension for PoseScript.</li>
                        <li>&#x2728; Presented at ECCV.</li>
                    </ul>
                </div>
            </div>

            <div class="bio-card">
                <div class="bio-date">2023</div>
                <div class="bio-list">
                    <ul>
                        <li>&#x2728; Presented at ICCV, DLBCN.</li>
                        <li>Attended <a href="https://iplab.dmi.unict.it/icvss2023/Home" target="_blank" rel="noopener noreferrer">ICVSS</a>.</li>
                    </ul>
                </div>
            </div>
            
            <div class="bio-card">
                <div class="bio-date">2022</div>
                <div class="bio-list">
                    <ul>
                        <li>&#x2728; Presented at ICLR, ECCV, DLBCN.</li>
                    </ul>
                </div>
            </div>
            
            <div class="bio-card">
                <div class="bio-date">2021</div>
                <div class="bio-list">
                    <ul>
                        <li>[December] Starting my PhD at <a href="https://www.iri.upc.edu/" target="_blank" rel="noopener noreferrer">IRI-UPC-CSIC</a> in collaboration with <a href="https://europe.naverlabs.com/" target="_blank" rel="noopener noreferrer">NAVER LABS Europe</a>, supervised by Francesc Moreno-Noguer, Philippe Weinzaepfel and Grégory Rogez.</li>
                    </ul>    
                </div>
            </div>

            <div class="bio-card">
                <div class="bio-date">2020</div>
                <div class="bio-list">
                    <ul>
                        <li>Internship at <a href="https://europe.naverlabs.com/" target="_blank" rel="noopener noreferrer">NAVER LABS Europe</a>, supervised by Diane Larlus and Rafael Sampaio De Rezende.</li>
                        <li>&#x1F393; Obtained the <a href="https://www.master-mva.com/" target="_blank" rel="noopener noreferrer">MVA master's degree</a>; from ENS Paris-Saclay and Institut Polytechnique de Paris.</li>
                        <li>&#x1F393; Graduated in Computer Science from <a href="https://www.telecom-paris.fr/" target="_blank" rel="noopener noreferrer">Télécom Paris</a> (French engineering school, equivalent to a master's degree).</li>
                    </ul>
                </div>
            </div>

        </div>

    </div>


</body>

</html>
